{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Quality Assessment for Face Verification in Video \n",
    "https://pdfs.semanticscholar.org/2c0a/caec54ab2585ff807e18b6b9550c44651eab.pdf?_ga=2.118968650.2116578973.1552199994-98267093.1547624592"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/vision/pose/lfw-youtube-experiments_v2'"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from detection.mtcnn import detect_face\n",
    "with tf.Graph().as_default():\n",
    "    sess = tf.Session()\n",
    "    pnet, rnet, onet = detect_face.create_mtcnn(sess, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The line_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext line_profiler\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "import line_profiler \n",
    "%load_ext line_profiler\n",
    "\n",
    "img = cv2.imread('alireza.jpg')\n",
    "gray = cv2.imread('alireza.jpg', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "minsize = 20 # minimum size of face\n",
    "threshold = [ 0.6, 0.7, 0.7 ]  # three steps's threshold\n",
    "factor = 0.709 # scale factor\n",
    "bounding_boxes, points = detect_face.detect_face(img, minsize, pnet, rnet, onet, threshold, factor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Illumination "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def illumination(gray):\n",
    "    # length of R available  range  of  gray  intensities  excluding  5%  of  the darkest  and  brightest  pixel\n",
    "    sorted_gray = np.sort(gray.ravel())\n",
    "    l = len(sorted_gray)\n",
    "    cut_off_idx = l * 5 // 100\n",
    "    r = sorted_gray[l-cut_off_idx] - sorted_gray[cut_off_idx]\n",
    "    return np.round(r / 255, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.86"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "illumination(gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sharpness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_contour(pts):\n",
    "    return np.array([[pts[i], pts[5 + i]] for i in  [0, 1, 4, 3]], np.int32).reshape((-1,1,2))\n",
    "\n",
    "def get_mask(image, contour):\n",
    "    mask = np.zeros(image.shape[0:2],dtype=\"uint8\")\n",
    "    cv2.drawContours(mask, [contour], -1, 255, -1)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def laplacian_over_mask(image, landmark):\n",
    "    zero = np.zeros_like(image)\n",
    "    contour = get_contour(landmark)\n",
    "    mask = get_mask(image, contour) #one-channel mask\n",
    "    mask = np.stack((mask,)*3, axis=-1) #3-channel mask\n",
    "    image = image.astype(np.uint8)\n",
    "    return cv2.bitwise_and(image, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.92"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sharpness(img, landmark):\n",
    "    contour = get_contour(landmark)\n",
    "    mask = get_mask(img, contour) #1-channel mask\n",
    "    mask = np.stack((mask,)*3, axis=-1) #3-channel mask\n",
    "    mask[mask == 255] = 1 # convert 0 and 255 to 0 and 1\n",
    "    laplacian = cv2.Laplacian(img,cv2.CV_64F)\n",
    "    edges = laplacian[mask.astype(bool)]\n",
    "    return np.round(edges.var() / 255 , 2)\n",
    "\n",
    "sharpness(img, points[:,0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
